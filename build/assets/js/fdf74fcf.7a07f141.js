"use strict";(self.webpackChunkmlops_documentation=self.webpackChunkmlops_documentation||[]).push([[109],{1332:function(e,n,r){r.r(n),r.d(n,{assets:function(){return l},contentTitle:function(){return d},default:function(){return h},frontMatter:function(){return a},metadata:function(){return s},toc:function(){return c}});var s=JSON.parse('{"id":"tools/message-queues","title":"Message Queues and Event Management","description":"Overview","source":"@site/docs/tools/message-queues.md","sourceDirName":"tools","slug":"/tools/message-queues","permalink":"/docs/tools/message-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/MLops-Project-Platform/documentation/tree/main/docs/tools/message-queues.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Databases","permalink":"/docs/tools/databases"}}'),i=r(4848),t=r(8453);const a={sidebar_position:5},d="Message Queues and Event Management",l={},c=[{value:"Overview",id:"overview",level:2},{value:"What Are Message Queues?",id:"what-are-message-queues",level:2},{value:"RabbitMQ",id:"rabbitmq",level:2},{value:"Core Concepts",id:"core-concepts",level:3},{value:"Use Cases in MLOps",id:"use-cases-in-mlops",level:3},{value:"Installation and Configuration",id:"installation-and-configuration",level:3},{value:"Usage Example",id:"usage-example",level:3},{value:"Key Features",id:"key-features",level:3},{value:"Best Practices",id:"best-practices",level:3},{value:"Apache Kafka",id:"apache-kafka",level:2},{value:"Core Concepts",id:"core-concepts-1",level:3},{value:"Architecture",id:"architecture",level:3},{value:"Use Cases in MLOps",id:"use-cases-in-mlops-1",level:3},{value:"Installation",id:"installation",level:3},{value:"Usage Example",id:"usage-example-1",level:3},{value:"Key Features",id:"key-features-1",level:3},{value:"When to Use Kafka vs RabbitMQ",id:"when-to-use-kafka-vs-rabbitmq",level:3},{value:"Comparison Table",id:"comparison-table",level:2},{value:"MLOps-Specific Patterns",id:"mlops-specific-patterns",level:2},{value:"Pattern 1: Training Job Queue",id:"pattern-1-training-job-queue",level:3},{value:"Pattern 2: Real-Time Feature Streaming",id:"pattern-2-real-time-feature-streaming",level:3},{value:"Pattern 3: Model Serving with Monitoring",id:"pattern-3-model-serving-with-monitoring",level:3},{value:"Best Practices",id:"best-practices-1",level:2},{value:"RabbitMQ",id:"rabbitmq-1",level:3},{value:"Kafka",id:"kafka",level:3},{value:"General Recommendations",id:"general-recommendations",level:3},{value:"Monitoring and Operations",id:"monitoring-and-operations",level:2},{value:"Key Metrics",id:"key-metrics",level:3},{value:"Health Checks",id:"health-checks",level:3},{value:"Redis as a Message Broker",id:"redis-as-a-message-broker",level:2},{value:"Redis Pub/Sub",id:"redis-pubsub",level:3},{value:"Installation",id:"installation-1",level:3},{value:"Pub/Sub Example",id:"pubsub-example",level:3},{value:"Redis Streams",id:"redis-streams",level:3},{value:"Streams Example",id:"streams-example",level:3},{value:"Key Redis Stream Commands",id:"key-redis-stream-commands",level:3},{value:"Redis Queue Libraries",id:"redis-queue-libraries",level:3},{value:"Redis vs Other Queues",id:"redis-vs-other-queues",level:3},{value:"Best Practices for Redis Queuing",id:"best-practices-for-redis-queuing",level:3},{value:"Further Reading",id:"further-reading",level:2}];function o(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"message-queues-and-event-management",children:"Message Queues and Event Management"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Message queues are essential for building scalable, decoupled systems in MLOps platforms. They enable asynchronous processing, ensure reliable message delivery, and decouple producers from consumers. This guide covers popular message queue solutions and their ML-specific applications."}),"\n",(0,i.jsx)(n.h2,{id:"what-are-message-queues",children:"What Are Message Queues?"}),"\n",(0,i.jsx)(n.p,{children:"Message queues provide a communication channel between different components of your system:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Producer \u2192 Message Queue \u2192 Consumer(s)\r\n  (Job)      (Buffer)      (Workers)\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Key Benefits:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Asynchronous processing"}),"\n",(0,i.jsx)(n.li,{children:"Decoupling of components"}),"\n",(0,i.jsx)(n.li,{children:"Scalability and load balancing"}),"\n",(0,i.jsx)(n.li,{children:"Reliability and message persistence"}),"\n",(0,i.jsx)(n.li,{children:"Multi-consumer support"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"rabbitmq",children:"RabbitMQ"}),"\n",(0,i.jsx)(n.p,{children:"RabbitMQ is a robust, feature-rich message broker built on the Advanced Message Queuing Protocol (AMQP)."}),"\n",(0,i.jsx)(n.h3,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Exchanges:"})," Route messages to queues"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Direct"}),": Route to specific queue by key"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fanout"}),": Broadcast to all queues"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Topic"}),": Route based on pattern matching"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Headers"}),": Route based on message headers"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Queues:"})," Store messages until consumed"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Bindings:"})," Connect exchanges to queues"]}),"\n",(0,i.jsx)(n.h3,{id:"use-cases-in-mlops",children:"Use Cases in MLOps"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Training Request \u2192 RabbitMQ \u2192 Training Worker Pool\r\n                      \u2193\r\n                 (multiple workers process in parallel)\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Typical Applications:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Distributed training job queuing"}),"\n",(0,i.jsx)(n.li,{children:"Model inference requests"}),"\n",(0,i.jsx)(n.li,{children:"Data pipeline orchestration"}),"\n",(0,i.jsx)(n.li,{children:"Experiment scheduling"}),"\n",(0,i.jsx)(n.li,{children:"Notification delivery (results, alerts)"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"installation-and-configuration",children:"Installation and Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# docker-compose.yml example\r\nrabbitmq:\r\n  image: rabbitmq:3.12-management\r\n  environment:\r\n    RABBITMQ_DEFAULT_USER: mlops\r\n    RABBITMQ_DEFAULT_PASS: password\r\n  ports:\r\n    - "5672:5672"      # AMQP port\r\n    - "15672:15672"    # Management UI\r\n  volumes:\r\n    - rabbitmq_data:/var/lib/rabbitmq\n'})}),"\n",(0,i.jsx)(n.h3,{id:"usage-example",children:"Usage Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import pika\r\nimport json\r\n\r\n# Connect to RabbitMQ\r\ncredentials = pika.PlainCredentials('mlops', 'password')\r\nconnection = pika.BlockingConnection(\r\n    pika.ConnectionParameters('rabbitmq', credentials=credentials)\r\n)\r\nchannel = connection.channel()\r\n\r\n# Declare queue\r\nchannel.queue_declare(queue='training_jobs', durable=True)\r\n\r\n# Publisher: Send training job\r\ndef submit_training_job(model_name, dataset):\r\n    message = {\r\n        'model': model_name,\r\n        'dataset': dataset,\r\n        'timestamp': str(datetime.now())\r\n    }\r\n    channel.basic_publish(\r\n        exchange='',\r\n        routing_key='training_jobs',\r\n        body=json.dumps(message),\r\n        properties=pika.BasicProperties(delivery_mode=2)  # Persistent\r\n    )\r\n    print(f\"Job submitted: {model_name}\")\r\n\r\n# Consumer: Process training jobs\r\ndef process_training_jobs():\r\n    def callback(ch, method, properties, body):\r\n        job = json.loads(body)\r\n        print(f\"Processing: {job['model']}\")\r\n        # Run training logic\r\n        train_model(job['model'], job['dataset'])\r\n        ch.basic_ack(delivery_tag=method.delivery_tag)\r\n    \r\n    channel.basic_qos(prefetch_count=1)\r\n    channel.basic_consume(queue='training_jobs', on_message_callback=callback)\r\n    channel.start_consuming()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"key-features",children:"Key Features"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Feature"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Durability"})}),(0,i.jsx)(n.td,{children:"Persists messages to disk"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Clustering"})}),(0,i.jsx)(n.td,{children:"Built-in clustering for HA"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Management UI"})}),(0,i.jsx)(n.td,{children:"Web-based administration"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Plugins"})}),(0,i.jsx)(n.td,{children:"Rich plugin ecosystem"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Protocol"})}),(0,i.jsx)(n.td,{children:"AMQP standard compliance"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Set ",(0,i.jsx)(n.code,{children:"durable=True"})," for critical jobs"]}),"\n",(0,i.jsx)(n.li,{children:"Use priority queues for urgent tasks"}),"\n",(0,i.jsx)(n.li,{children:"Implement message TTL for time-sensitive data"}),"\n",(0,i.jsx)(n.li,{children:"Monitor queue depth and consumer lag"}),"\n",(0,i.jsx)(n.li,{children:"Use separate exchanges for different message types"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"apache-kafka",children:"Apache Kafka"}),"\n",(0,i.jsx)(n.p,{children:"Kafka is a distributed event streaming platform designed for high-throughput, low-latency messaging."}),"\n",(0,i.jsx)(n.h3,{id:"core-concepts-1",children:"Core Concepts"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Topics:"})," Named logs of messages organized by partition"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Partitions:"})," Parallel processing units within a topic"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Consumer Groups:"})," Distribute message consumption across workers"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Brokers:"})," Kafka server instances in a cluster"]}),"\n",(0,i.jsx)(n.h3,{id:"architecture",children:"Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Topic: training_events\r\n\u251c\u2500\u2500 Partition 0 \u2500\u2500\u2192 Consumer 1\r\n\u251c\u2500\u2500 Partition 1 \u2500\u2500\u2192 Consumer 2\r\n\u251c\u2500\u2500 Partition 2 \u2500\u2500\u2192 Consumer 3\r\n\u2514\u2500\u2500 Partition 3 \u2500\u2500\u2192 Consumer 1\n"})}),"\n",(0,i.jsx)(n.h3,{id:"use-cases-in-mlops-1",children:"Use Cases in MLOps"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"High-Volume Event Streaming:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Model inference requests at scale"}),"\n",(0,i.jsx)(n.li,{children:"Real-time feature computation"}),"\n",(0,i.jsx)(n.li,{children:"Continuous model monitoring"}),"\n",(0,i.jsx)(n.li,{children:"Data pipeline events"}),"\n",(0,i.jsx)(n.li,{children:"Distributed training job coordination"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example Scenario:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"User Requests \u2192 Kafka Topic \u2192 \r\n  \u251c\u2192 Model Serving Consumer\r\n  \u251c\u2192 Monitoring Consumer\r\n  \u2514\u2192 Analytics Consumer\n"})}),"\n",(0,i.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# docker-compose.yml\r\nzookeeper:\r\n  image: confluentinc/cp-zookeeper:7.5.0\r\n  environment:\r\n    ZOOKEEPER_CLIENT_PORT: 2181\r\n\r\nkafka:\r\n  image: confluentinc/cp-kafka:7.5.0\r\n  depends_on:\r\n    - zookeeper\r\n  environment:\r\n    KAFKA_BROKER_ID: 1\r\n    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\r\n    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092\r\n    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\r\n    KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\r\n    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\r\n  ports:\r\n    - "9092:9092"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"usage-example-1",children:"Usage Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from kafka import KafkaProducer, KafkaConsumer\r\nimport json\r\n\r\n# Producer: Send inference requests\r\nproducer = KafkaProducer(\r\n    bootstrap_servers=['localhost:9092'],\r\n    value_serializer=lambda v: json.dumps(v).encode('utf-8')\r\n)\r\n\r\ndef submit_inference_request(model_id, input_data):\r\n    event = {\r\n        'model_id': model_id,\r\n        'input': input_data,\r\n        'timestamp': str(datetime.now())\r\n    }\r\n    producer.send('inference_requests', event)\r\n\r\n# Consumer: Process inference requests\r\nconsumer = KafkaConsumer(\r\n    'inference_requests',\r\n    bootstrap_servers=['localhost:9092'],\r\n    group_id='inference_workers',\r\n    value_deserializer=lambda m: json.loads(m.decode('utf-8')),\r\n    auto_offset_reset='earliest'\r\n)\r\n\r\nfor event in consumer:\r\n    request = event.value\r\n    prediction = model.predict(request['input'])\r\n    save_prediction(request['model_id'], prediction)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"key-features-1",children:"Key Features"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Feature"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Throughput"})}),(0,i.jsx)(n.td,{children:"Millions of messages/second"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Durability"})}),(0,i.jsx)(n.td,{children:"Configurable retention periods"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Scalability"})}),(0,i.jsx)(n.td,{children:"Horizontal scaling via partitions"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Fault Tolerance"})}),(0,i.jsx)(n.td,{children:"Replication across brokers"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Ordering"})}),(0,i.jsx)(n.td,{children:"Per-partition message ordering"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"when-to-use-kafka-vs-rabbitmq",children:"When to Use Kafka vs RabbitMQ"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Kafka"}),(0,i.jsx)(n.th,{children:"RabbitMQ"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Throughput"})}),(0,i.jsx)(n.td,{children:"Ultra-high"}),(0,i.jsx)(n.td,{children:"High"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Latency"})}),(0,i.jsx)(n.td,{children:"Lower"}),(0,i.jsx)(n.td,{children:"Lower"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Complexity"})}),(0,i.jsx)(n.td,{children:"Higher"}),(0,i.jsx)(n.td,{children:"Lower"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Storage"})}),(0,i.jsx)(n.td,{children:"Persistent log"}),(0,i.jsx)(n.td,{children:"In-memory/persistent"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Replayability"})}),(0,i.jsx)(n.td,{children:"Built-in"}),(0,i.jsx)(n.td,{children:"Not native"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Setup"})}),(0,i.jsx)(n.td,{children:"Complex"}),(0,i.jsx)(n.td,{children:"Simple"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"comparison-table",children:"Comparison Table"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Feature"}),(0,i.jsx)(n.th,{children:"RabbitMQ"}),(0,i.jsx)(n.th,{children:"Kafka"}),(0,i.jsx)(n.th,{children:"AWS SQS"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Message Ordering"})}),(0,i.jsx)(n.td,{children:"Per-queue"}),(0,i.jsx)(n.td,{children:"Per-partition"}),(0,i.jsx)(n.td,{children:"FIFO queues"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Throughput"})}),(0,i.jsx)(n.td,{children:"High"}),(0,i.jsx)(n.td,{children:"Ultra-high"}),(0,i.jsx)(n.td,{children:"High"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Persistence"})}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes (log-based)"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Latency"})}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Low"}),(0,i.jsx)(n.td,{children:"Medium"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Clustering"})}),(0,i.jsx)(n.td,{children:"Built-in"}),(0,i.jsx)(n.td,{children:"Built-in"}),(0,i.jsx)(n.td,{children:"Managed"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Message Replay"})}),(0,i.jsx)(n.td,{children:"Limited"}),(0,i.jsx)(n.td,{children:"Full history"}),(0,i.jsx)(n.td,{children:"No"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Learning Curve"})}),(0,i.jsx)(n.td,{children:"Medium"}),(0,i.jsx)(n.td,{children:"Steep"}),(0,i.jsx)(n.td,{children:"Low"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"mlops-specific-patterns",children:"MLOps-Specific Patterns"}),"\n",(0,i.jsx)(n.h3,{id:"pattern-1-training-job-queue",children:"Pattern 1: Training Job Queue"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Submit training jobs to queue\r\njob = {\r\n    'job_id': uuid4(),\r\n    'model': 'bert-v2',\r\n    'dataset': 'wiki-2024',\r\n    'hyperparams': {'batch_size': 32, 'lr': 0.001},\r\n    'priority': 'high'\r\n}\r\nqueue.publish('training_jobs', job)\r\n\r\n# Workers consume and process\r\nwhile True:\r\n    job = queue.consume('training_jobs')\r\n    train_and_log_model(job)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"pattern-2-real-time-feature-streaming",children:"Pattern 2: Real-Time Feature Streaming"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Stream raw events\r\nraw_events_producer.send('raw_events', raw_data)\r\n\r\n# Multiple feature processors\r\nfeature_processor1.subscribe('raw_events')  # Extract feature_x\r\nfeature_processor2.subscribe('raw_events')  # Extract feature_y\r\nfeature_processor3.subscribe('raw_events')  # Extract feature_z\r\n\r\n# All computed features go to feature store\n"})}),"\n",(0,i.jsx)(n.h3,{id:"pattern-3-model-serving-with-monitoring",children:"Pattern 3: Model Serving with Monitoring"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Inference Requests \r\n    \u2193\r\n  Kafka Topic\r\n    \u251c\u2192 Model Server (returns prediction)\r\n    \u251c\u2192 Monitoring (logs metrics)\r\n    \u2514\u2192 Analytics (data collection)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-1",children:"Best Practices"}),"\n",(0,i.jsx)(n.h3,{id:"rabbitmq-1",children:"RabbitMQ"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use separate exchanges for different domains"}),"\n",(0,i.jsx)(n.li,{children:"Implement dead-letter exchanges for failed messages"}),"\n",(0,i.jsx)(n.li,{children:"Set appropriate prefetch counts"}),"\n",(0,i.jsx)(n.li,{children:"Monitor queue lengths for bottlenecks"}),"\n",(0,i.jsx)(n.li,{children:"Use priority queues for urgent tasks"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"kafka",children:"Kafka"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Plan partition count based on throughput"}),"\n",(0,i.jsx)(n.li,{children:"Monitor consumer lag continuously"}),"\n",(0,i.jsx)(n.li,{children:"Implement proper offset management"}),"\n",(0,i.jsx)(n.li,{children:"Use schema registry for message validation"}),"\n",(0,i.jsx)(n.li,{children:"Configure retention policies appropriately"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"general-recommendations",children:"General Recommendations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dead Letter Handling:"})," Route failed messages to DLQ for investigation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Message Format:"})," Use structured formats (JSON, Protobuf, Avro)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitoring:"})," Track queue depth, throughput, latency"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Alerting:"})," Alert on high queue depth or consumer lag"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Governance:"})," Document message schemas and ownership"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"monitoring-and-operations",children:"Monitoring and Operations"}),"\n",(0,i.jsx)(n.h3,{id:"key-metrics",children:"Key Metrics"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# RabbitMQ metrics\r\n- Queue length\r\n- Message rate (in/out)\r\n- Consumer count\r\n- Memory usage\r\n- Disk usage\r\n\r\n# Kafka metrics\r\n- Consumer lag per topic/partition\r\n- Throughput (msgs/sec)\r\n- Replication lag\r\n- Broker health\r\n- Producer batch size\n"})}),"\n",(0,i.jsx)(n.h3,{id:"health-checks",children:"Health Checks"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# RabbitMQ health\r\nimport requests\r\nhealth = requests.get('http://rabbitmq:15672/api/health/checks/virtual-hosts')\r\n\r\n# Kafka health\r\nfrom kafka.admin import KafkaAdminClient\r\nadmin = KafkaAdminClient(bootstrap_servers=['localhost:9092'])\r\ncluster_metadata = admin.describe_cluster()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"redis-as-a-message-broker",children:"Redis as a Message Broker"}),"\n",(0,i.jsxs)(n.p,{children:["While Redis is primarily a caching layer (detailed in the ",(0,i.jsx)(n.a,{href:"/docs/tools/databases",children:"Databases guide"}),"), it also provides pub/sub and stream capabilities for lightweight message queuing."]}),"\n",(0,i.jsx)(n.h3,{id:"redis-pubsub",children:"Redis Pub/Sub"}),"\n",(0,i.jsx)(n.p,{children:"Redis Pub/Sub is a simple publish-subscribe mechanism for real-time messaging."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Use Cases:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Real-time notifications"}),"\n",(0,i.jsx)(n.li,{children:"Broadcasting to multiple subscribers"}),"\n",(0,i.jsx)(n.li,{children:"Live dashboard updates"}),"\n",(0,i.jsx)(n.li,{children:"Lightweight event distribution"}),"\n",(0,i.jsx)(n.li,{children:"Cache invalidation signals"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Limitations:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Messages are not persisted (lost if no subscribers)"}),"\n",(0,i.jsx)(n.li,{children:"No delivery guarantees"}),"\n",(0,i.jsx)(n.li,{children:"Not suitable for critical job queuing"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"installation-1",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'# docker-compose.yml\r\nredis:\r\n  image: redis:7-alpine\r\n  ports:\r\n    - "6379:6379"\r\n  volumes:\r\n    - redis_data:/data\r\n  command: redis-server --appendonly yes\n'})}),"\n",(0,i.jsx)(n.h3,{id:"pubsub-example",children:"Pub/Sub Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import redis\r\nimport json\r\nfrom threading import Thread\r\n\r\n# Publisher\r\ndef publish_event(event_type, data):\r\n    r = redis.Redis(host='redis', port=6379)\r\n    message = {\r\n        'type': event_type,\r\n        'data': data,\r\n        'timestamp': str(datetime.now())\r\n    }\r\n    r.publish('mlops_events', json.dumps(message))\r\n    print(f\"Published: {event_type}\")\r\n\r\n# Subscriber\r\ndef subscribe_to_events():\r\n    r = redis.Redis(host='redis', port=6379)\r\n    pubsub = r.pubsub()\r\n    pubsub.subscribe('mlops_events')\r\n    \r\n    print(\"Listening for events...\")\r\n    for message in pubsub.listen():\r\n        if message['type'] == 'message':\r\n            event = json.loads(message['data'])\r\n            handle_event(event)\r\n\r\n# Usage\r\npublish_event('model_trained', {'model': 'bert-v2', 'accuracy': 0.95})\r\n\r\n# Start subscriber in background\r\nsubscriber_thread = Thread(target=subscribe_to_events, daemon=True)\r\nsubscriber_thread.start()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"redis-streams",children:"Redis Streams"}),"\n",(0,i.jsx)(n.p,{children:"Redis Streams provide a more reliable message queuing mechanism with persistence and consumer groups."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Use Cases:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Lightweight job queues"}),"\n",(0,i.jsx)(n.li,{children:"Log aggregation"}),"\n",(0,i.jsx)(n.li,{children:"Event sourcing"}),"\n",(0,i.jsx)(n.li,{children:"Time-series event storage"}),"\n",(0,i.jsx)(n.li,{children:"Consumer group-based processing"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Advantages over Pub/Sub:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Message persistence"}),"\n",(0,i.jsx)(n.li,{children:"Consumer groups with acknowledgment"}),"\n",(0,i.jsx)(n.li,{children:"Message replay capability"}),"\n",(0,i.jsx)(n.li,{children:"Backpressure handling"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"streams-example",children:"Streams Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import redis\r\nimport json\r\n\r\nr = redis.Redis(host='redis', port=6379, decode_responses=True)\r\n\r\n# Producer: Add messages to stream\r\ndef add_to_stream(stream_key, message):\r\n    msg_id = r.xadd(stream_key, {\r\n        'data': json.dumps(message),\r\n        'timestamp': str(datetime.now())\r\n    })\r\n    print(f\"Added to stream: {msg_id}\")\r\n    return msg_id\r\n\r\n# Consumer: Create consumer group and read messages\r\ndef create_consumer_group(stream_key, group_name):\r\n    try:\r\n        r.xgroup_create(stream_key, group_name, id='0', mkstream=True)\r\n    except redis.ResponseError:\r\n        pass  # Group already exists\r\n\r\ndef consume_stream(stream_key, group_name, consumer_name):\r\n    while True:\r\n        # Read messages from the group\r\n        messages = r.xreadgroup(\r\n            {stream_key: '>'},\r\n            group_name,\r\n            consumer_name,\r\n            count=1,\r\n            block=0\r\n        )\r\n        \r\n        for stream, stream_messages in messages:\r\n            for msg_id, msg_data in stream_messages:\r\n                try:\r\n                    # Process message\r\n                    data = json.loads(msg_data['data'])\r\n                    process_training_job(data)\r\n                    \r\n                    # Acknowledge successful processing\r\n                    r.xack(stream_key, group_name, msg_id)\r\n                    print(f\"Processed and acked: {msg_id}\")\r\n                except Exception as e:\r\n                    print(f\"Error processing message: {e}\")\r\n\r\n# Setup\r\nstream_key = 'training_jobs'\r\ngroup_name = 'job_processors'\r\nconsumer_name = 'worker_1'\r\n\r\ncreate_consumer_group(stream_key, group_name)\r\n\r\n# Add jobs\r\nadd_to_stream(stream_key, {'model': 'bert', 'dataset': 'wiki'})\r\nadd_to_stream(stream_key, {'model': 'gpt', 'dataset': 'books'})\r\n\r\n# Consume in background\r\nThread(target=consume_stream, args=(stream_key, group_name, consumer_name), daemon=True).start()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"key-redis-stream-commands",children:"Key Redis Stream Commands"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Command"}),(0,i.jsx)(n.th,{children:"Purpose"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XADD"})}),(0,i.jsx)(n.td,{children:"Add message to stream"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XREAD"})}),(0,i.jsx)(n.td,{children:"Read messages from stream"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XGROUP CREATE"})}),(0,i.jsx)(n.td,{children:"Create consumer group"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XREADGROUP"})}),(0,i.jsx)(n.td,{children:"Read as consumer group member"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XACK"})}),(0,i.jsx)(n.td,{children:"Acknowledge message processing"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XPENDING"})}),(0,i.jsx)(n.td,{children:"Check pending messages"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XCLAIM"})}),(0,i.jsx)(n.td,{children:"Claim message from other consumer"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"XLEN"})}),(0,i.jsx)(n.td,{children:"Get stream length"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"redis-queue-libraries",children:"Redis Queue Libraries"}),"\n",(0,i.jsx)(n.p,{children:"Popular Python libraries for Redis-based queuing:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"RQ (Redis Queue)"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from rq import Queue\r\nfrom redis import Redis\r\n\r\nq = Queue(connection=Redis())\r\n\r\n# Enqueue job\r\njob = q.enqueue('path.to.train_model', model_name='bert')\r\n\r\n# Job status\r\nprint(job.get_status())\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Celery with Redis"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from celery import Celery\r\n\r\napp = Celery('mlops', broker='redis://redis:6379')\r\n\r\n@app.task\r\ndef train_model(model_name):\r\n    # Training logic\r\n    return f\"Model {model_name} trained\"\r\n\r\n# Queue task\r\ntrain_model.delay('bert-v2')\n"})}),"\n",(0,i.jsx)(n.h3,{id:"redis-vs-other-queues",children:"Redis vs Other Queues"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Redis Streams"}),(0,i.jsx)(n.th,{children:"RabbitMQ"}),(0,i.jsx)(n.th,{children:"Kafka"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Setup Complexity"})}),(0,i.jsx)(n.td,{children:"Simple"}),(0,i.jsx)(n.td,{children:"Medium"}),(0,i.jsx)(n.td,{children:"Complex"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Throughput"})}),(0,i.jsx)(n.td,{children:"High"}),(0,i.jsx)(n.td,{children:"High"}),(0,i.jsx)(n.td,{children:"Ultra-high"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Persistence"})}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Consumer Groups"})}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Message Replay"})}),(0,i.jsx)(n.td,{children:"Yes"}),(0,i.jsx)(n.td,{children:"Limited"}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Clustering"})}),(0,i.jsx)(n.td,{children:"Yes (Cluster)"}),(0,i.jsx)(n.td,{children:"Built-in"}),(0,i.jsx)(n.td,{children:"Built-in"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Dependencies"})}),(0,i.jsx)(n.td,{children:"Minimal"}),(0,i.jsx)(n.td,{children:"Erlang"}),(0,i.jsx)(n.td,{children:"Java"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Use Case"})}),(0,i.jsx)(n.td,{children:"Lightweight queuing"}),(0,i.jsx)(n.td,{children:"Robust messaging"}),(0,i.jsx)(n.td,{children:"High-throughput streaming"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"best-practices-for-redis-queuing",children:"Best Practices for Redis Queuing"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Enable Persistence"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Use both RDB and AOF for durability\r\nappendonly yes\r\nsave 900 1\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Consumer Group Management"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Monitor pending messages\r\npending = r.xpending(stream_key, group_name)\r\nprint(f\"Pending messages: {pending['num-pending']}\")\r\n\r\n# Claim stale messages\r\nr.xclaim(stream_key, group_name, consumer_name, min_idle_time=3600000)\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Stream Trimming"})," - Prevent unbounded growth"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Keep last 1 million messages\r\nr.xtrim(stream_key, maxlen=1000000)\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Monitoring"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Check stream health\r\nstream_info = r.xinfo_stream(stream_key)\r\nprint(f\"Stream length: {stream_info['length']}\")\r\nprint(f\"Consumer groups: {stream_info['groups']}\")\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.rabbitmq.com/documentation.html",children:"RabbitMQ Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://kafka.apache.org/documentation/",children:"Apache Kafka Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://redis.io/docs/data-types/streams/",children:"Redis Streams Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.cloudamqp.com/blog/kafka-vs-rabbitmq.html",children:"Kafka vs RabbitMQ Comparison"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://martinfowler.com/articles/patterns-of-distributed-systems/",children:"Event Streaming Patterns"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://python-rq.org/",children:"Redis Queue (RQ)"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.celeryproject.io/",children:"Celery Documentation"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(o,{...e})}):o(e)}},8453:function(e,n,r){r.d(n,{R:function(){return a},x:function(){return d}});var s=r(6540);const i={},t=s.createContext(i);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);