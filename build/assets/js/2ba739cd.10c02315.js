"use strict";(self.webpackChunkmlops_documentation=self.webpackChunkmlops_documentation||[]).push([[7422],{2902:function(e,r,n){n.r(r),n.d(r,{assets:function(){return l},contentTitle:function(){return a},default:function(){return p},frontMatter:function(){return o},metadata:function(){return s},toc:function(){return d}});var s=JSON.parse('{"id":"tools/redis","title":"Redis","description":"Overview","source":"@site/docs/tools/redis.md","sourceDirName":"tools","slug":"/tools/redis","permalink":"/docs/tools/redis","draft":false,"unlisted":false,"editUrl":"https://github.com/MLops-Project-Platform/documentation/tree/main/docs/tools/redis.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Amazon DynamoDB","permalink":"/docs/tools/dynamodb"},"next":{"title":"Memcached","permalink":"/docs/tools/memcached"}}'),i=n(4848),t=n(8453);const o={sidebar_position:1},a="Redis",l={},d=[{value:"Overview",id:"overview",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Use Cases in MLOps",id:"use-cases-in-mlops",level:2},{value:"Caching Training Metrics",id:"caching-training-metrics",level:3},{value:"Session Management",id:"session-management",level:3},{value:"Installation",id:"installation",level:2},{value:"Docker",id:"docker",level:3},{value:"Redis Cluster Setup",id:"redis-cluster-setup",level:3},{value:"Data Structures",id:"data-structures",level:2},{value:"Strings",id:"strings",level:3},{value:"Lists",id:"lists",level:3},{value:"Sets",id:"sets",level:3},{value:"Sorted Sets",id:"sorted-sets",level:3},{value:"Hashes",id:"hashes",level:3},{value:"Persistence",id:"persistence",level:2},{value:"RDB (Snapshots)",id:"rdb-snapshots",level:3},{value:"AOF (Append-Only File)",id:"aof-append-only-file",level:3},{value:"Replication",id:"replication",level:2},{value:"Master-Slave Setup",id:"master-slave-setup",level:3},{value:"Python Connection with Replication",id:"python-connection-with-replication",level:3},{value:"Clustering",id:"clustering",level:2},{value:"Redis Cluster Operations",id:"redis-cluster-operations",level:3},{value:"Pub/Sub",id:"pubsub",level:2},{value:"Message Publishing",id:"message-publishing",level:3},{value:"Streams",id:"streams",level:2},{value:"Event Streaming",id:"event-streaming",level:3},{value:"Monitoring",id:"monitoring",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Further Reading",id:"further-reading",level:2}];function c(e){const r={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"redis",children:"Redis"})}),"\n",(0,i.jsx)(r.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(r.p,{children:"Redis is an in-memory data structure store used for caching, session storage, and real-time analytics. It provides exceptional performance and flexibility for MLOps caching layers."}),"\n",(0,i.jsx)(r.h2,{id:"key-features",children:"Key Features"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"In-Memory"})," - Ultra-fast operations (microsecond latency)"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Multiple Data Types"})," - Strings, Lists, Sets, Sorted Sets, Hashes, Streams"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Persistence Options"})," - RDB snapshots or AOF logs"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Replication"})," - Master-slave replication for HA"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Cluster Mode"})," - Horizontal scaling across nodes"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"TTL Support"})," - Auto-expiration of keys"]}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"use-cases-in-mlops",children:"Use Cases in MLOps"}),"\n",(0,i.jsx)(r.h3,{id:"caching-training-metrics",children:"Caching Training Metrics"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\nimport json\r\n\r\nr = redis.Redis(host='localhost', port=6379, db=0)\r\n\r\n# Cache experiment metrics\r\nexperiment_id = 'exp_001'\r\nmetrics = {\r\n    'accuracy': 0.95,\r\n    'loss': 0.05,\r\n    'f1_score': 0.93\r\n}\r\n\r\n# Cache with 1-hour expiration\r\nr.setex(f'metrics:{experiment_id}', 3600, json.dumps(metrics))\r\n\r\n# Retrieve from cache\r\ncached = r.get(f'metrics:{experiment_id}')\r\nif cached:\r\n    metrics = json.loads(cached)\n"})}),"\n",(0,i.jsx)(r.h3,{id:"session-management",children:"Session Management"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\n\r\nr = redis.Redis(host='localhost', port=6379, db=0)\r\n\r\n# Store user session\r\nsession_data = {\r\n    'user_id': 'user_123',\r\n    'experiment_id': 'exp_001',\r\n    'login_time': '2024-01-15T10:30:00'\r\n}\r\n\r\n# Session expires in 1 hour\r\nr.hset(f'session:user_123', mapping={\r\n    'user_id': 'user_123',\r\n    'experiment_id': 'exp_001',\r\n    'login_time': '2024-01-15T10:30:00'\r\n})\r\nr.expire(f'session:user_123', 3600)\r\n\r\n# Check session\r\nif r.exists(f'session:user_123'):\r\n    session = r.hgetall(f'session:user_123')\n"})}),"\n",(0,i.jsx)(r.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(r.h3,{id:"docker",children:"Docker"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-yaml",children:'version: \'3.8\'\r\nservices:\r\n  redis:\r\n    image: redis:7-alpine\r\n    ports:\r\n      - "6379:6379"\r\n    command: redis-server --appendonly yes\r\n    volumes:\r\n      - redis_data:/data\r\n    healthcheck:\r\n      test: ["CMD", "redis-cli", "ping"]\r\n      interval: 10s\r\n      timeout: 5s\r\n      retries: 5\r\n\r\nvolumes:\r\n  redis_data:\n'})}),"\n",(0,i.jsx)(r.h3,{id:"redis-cluster-setup",children:"Redis Cluster Setup"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-yaml",children:'version: \'3.8\'\r\nservices:\r\n  redis-1:\r\n    image: redis:7-alpine\r\n    ports:\r\n      - "6379:6379"\r\n    command: redis-server --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes\r\n    \r\n  redis-2:\r\n    image: redis:7-alpine\r\n    ports:\r\n      - "6380:6379"\r\n    command: redis-server --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes\r\n    \r\n  redis-3:\r\n    image: redis:7-alpine\r\n    ports:\r\n      - "6381:6379"\r\n    command: redis-server --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --appendonly yes\n'})}),"\n",(0,i.jsx)(r.h2,{id:"data-structures",children:"Data Structures"}),"\n",(0,i.jsx)(r.h3,{id:"strings",children:"Strings"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\n\r\nr = redis.Redis(host='localhost', port=6379)\r\n\r\n# Simple key-value\r\nr.set('model_version', '1.0')\r\nversion = r.get('model_version').decode('utf-8')\r\n\r\n# Increment/Decrement\r\nr.incr('request_count')  # Atomic counter\r\nr.decr('remaining_quota')\r\n\r\n# Append\r\nr.append('logs', 'new log entry\\n')\r\n\r\n# Get and set with expiration\r\nr.setex('temp_token', 300, 'token_abc123')  # 5 minutes\r\n\r\n# Multiple operations\r\nr.mset({\r\n    'model_name': 'bert',\r\n    'version': '2.0',\r\n    'accuracy': '0.95'\r\n})\r\n\r\nvalues = r.mget('model_name', 'version', 'accuracy')\n"})}),"\n",(0,i.jsx)(r.h3,{id:"lists",children:"Lists"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"# Job queue\r\nr.rpush('job_queue', 'job_1', 'job_2', 'job_3')  # Push to tail\r\njob = r.lpop('job_queue')  # Pop from head (FIFO)\r\n\r\n# Blocking operations (wait for jobs)\r\njob = r.blpop('job_queue', timeout=30)  # Wait max 30 seconds\r\n\r\n# List operations\r\nr.llen('job_queue')  # Queue length\r\nr.lrange('job_queue', 0, -1)  # Get all elements\n"})}),"\n",(0,i.jsx)(r.h3,{id:"sets",children:"Sets"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"# Tag management\r\nr.sadd('exp_001:tags', 'nlp', 'classification', 'bert')\r\nr.sadd('exp_002:tags', 'nlp', 'generation', 'gpt')\r\n\r\n# Common tags\r\ncommon = r.sinter('exp_001:tags', 'exp_002:tags')  # Intersection\r\n\r\n# All tags\r\nall_tags = r.sunion('exp_001:tags', 'exp_002:tags')  # Union\r\n\r\n# Check membership\r\nif r.sismember('exp_001:tags', 'nlp'):\r\n    print(\"Experiment uses NLP\")\n"})}),"\n",(0,i.jsx)(r.h3,{id:"sorted-sets",children:"Sorted Sets"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"# Leaderboard (experiments by accuracy)\r\nr.zadd('accuracy_leaderboard', {\r\n    'exp_001': 0.95,\r\n    'exp_002': 0.92,\r\n    'exp_003': 0.98\r\n})\r\n\r\n# Top 3 experiments\r\ntop_3 = r.zrange('accuracy_leaderboard', -3, -1, withscores=True)\r\n\r\n# Experiments with accuracy > 0.9\r\ngood = r.zrangebyscore('accuracy_leaderboard', 0.9, 0.99)\r\n\r\n# Add to leaderboard\r\nr.zincrby('accuracy_leaderboard', 0.01, 'exp_001')  # Improve score\n"})}),"\n",(0,i.jsx)(r.h3,{id:"hashes",children:"Hashes"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"# Store structured data\r\nr.hset('exp_001', mapping={\r\n    'name': 'BERT Classifier',\r\n    'accuracy': '0.95',\r\n    'loss': '0.05',\r\n    'created_at': '2024-01-15'\r\n})\r\n\r\n# Get field\r\nname = r.hget('exp_001', 'name')\r\n\r\n# Get all fields\r\nexp = r.hgetall('exp_001')\r\n\r\n# Increment field\r\nr.hincrby('exp_001', 'epoch', 1)\n"})}),"\n",(0,i.jsx)(r.h2,{id:"persistence",children:"Persistence"}),"\n",(0,i.jsx)(r.h3,{id:"rdb-snapshots",children:"RDB (Snapshots)"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\n\r\nr = redis.Redis(host='localhost', port=6379)\r\n\r\n# Trigger snapshot\r\nr.bgsave()  # Background save\r\n\r\n# Force synchronous save\r\nr.save()  # Blocks until done\r\n\r\n# Check last save time\r\nlast_save = r.lastsave()\n"})}),"\n",(0,i.jsx)(r.h3,{id:"aof-append-only-file",children:"AOF (Append-Only File)"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# In redis.conf or container command\r\nredis-server --appendonly yes --appendfsync everysec\r\n\r\n# Rewrite AOF file\r\nredis-cli BGREWRITEAOF\r\n\r\n# Verify AOF file\r\nredis-check-aof /var/lib/redis/appendonly.aof\n"})}),"\n",(0,i.jsx)(r.h2,{id:"replication",children:"Replication"}),"\n",(0,i.jsx)(r.h3,{id:"master-slave-setup",children:"Master-Slave Setup"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Master node (default configuration)\r\nredis-server --port 6379\r\n\r\n# Slave node\r\nredis-server --port 6380 --replicaof localhost 6379\r\n\r\n# Verify replication\r\nredis-cli -p 6380 INFO replication\n"})}),"\n",(0,i.jsx)(r.h3,{id:"python-connection-with-replication",children:"Python Connection with Replication"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\n\r\n# Connect to master (write)\r\nmaster = redis.Redis(host='master', port=6379)\r\n\r\n# Connect to replica (read)\r\nreplica = redis.Redis(host='replica', port=6380)\r\n\r\n# Write to master\r\nmaster.set('key', 'value')\r\n\r\n# Read from replica (eventually consistent)\r\nvalue = replica.get('key')\n"})}),"\n",(0,i.jsx)(r.h2,{id:"clustering",children:"Clustering"}),"\n",(0,i.jsx)(r.h3,{id:"redis-cluster-operations",children:"Redis Cluster Operations"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'from redis.cluster import RedisCluster\r\n\r\n# Connect to cluster\r\nrc = RedisCluster(startup_nodes=[\r\n    {"host": "127.0.0.1", "port": "6379"},\r\n    {"host": "127.0.0.1", "port": "6380"},\r\n    {"host": "127.0.0.1", "port": "6381"}\r\n])\r\n\r\n# Data automatically distributed\r\nrc.set(\'key1\', \'value1\')\r\nvalue = rc.get(\'key1\')\r\n\r\n# Cluster info\r\nprint(rc.cluster_info())\r\nprint(rc.cluster_nodes())\n'})}),"\n",(0,i.jsx)(r.h2,{id:"pubsub",children:"Pub/Sub"}),"\n",(0,i.jsx)(r.h3,{id:"message-publishing",children:"Message Publishing"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\nimport threading\r\n\r\nr = redis.Redis(host='localhost', port=6379)\r\n\r\n# Subscriber\r\ndef subscriber():\r\n    pubsub = r.pubsub()\r\n    pubsub.subscribe('training_updates')\r\n    \r\n    for message in pubsub.listen():\r\n        if message['type'] == 'message':\r\n            print(f\"Received: {message['data']}\")\r\n\r\n# Publisher\r\ndef publisher():\r\n    for i in range(5):\r\n        r.publish('training_updates', f'Epoch {i+1} completed')\r\n\r\n# Run in threads\r\nsub_thread = threading.Thread(target=subscriber)\r\npub_thread = threading.Thread(target=publisher)\r\nsub_thread.start()\r\npub_thread.start()\n"})}),"\n",(0,i.jsx)(r.h2,{id:"streams",children:"Streams"}),"\n",(0,i.jsx)(r.h3,{id:"event-streaming",children:"Event Streaming"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\nfrom datetime import datetime\r\n\r\nr = redis.Redis(host='localhost', port=6379)\r\n\r\n# Add event to stream\r\nevent_id = r.xadd('training_events', {\r\n    'experiment_id': 'exp_001',\r\n    'event': 'epoch_completed',\r\n    'epoch': '5',\r\n    'loss': '0.05',\r\n    'timestamp': str(datetime.now())\r\n})\r\n\r\n# Read stream\r\nevents = r.xrange('training_events')\r\nfor event_id, data in events:\r\n    print(f\"{event_id}: {data}\")\r\n\r\n# Read specific range\r\nrecent = r.xrange('training_events', '-', '+', count=10)\r\n\r\n# Consumer group (for processing)\r\nr.xgroup_create('training_events', 'processor_group', '$', mkstream=True)\r\n\r\n# Read as consumer\r\nmessages = r.xreadgroup({'training_events': '>'}, 'processor_group', 'processor_1', count=1)\r\n\r\n# Acknowledge processing\r\nr.xack('training_events', 'processor_group', event_id)\n"})}),"\n",(0,i.jsx)(r.h2,{id:"monitoring",children:"Monitoring"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import redis\r\n\r\nr = redis.Redis(host='localhost', port=6379)\r\n\r\n# Server info\r\ninfo = r.info()\r\nprint(f\"Used memory: {info['used_memory_human']}\")\r\nprint(f\"Connected clients: {info['connected_clients']}\")\r\nprint(f\"Total commands: {info['total_commands_processed']}\")\r\n\r\n# Monitor commands\r\ndef monitor():\r\n    for cmd in r.monitor():\r\n        print(f\"[{cmd[0]}] {cmd[1]}\")\r\n\r\n# Client info\r\nclients = r.client_list()\r\n\r\n# Key space stats\r\ndbsize = r.dbsize()\r\nkeys_by_pattern = r.keys('exp_*')\n"})}),"\n",(0,i.jsx)(r.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(r.ol,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Use connection pooling"})," - Reuse connections"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Pipeline operations"})," - Batch commands"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Implement TTL"})," - Prevent unbounded memory growth"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Monitor memory"})," - Use maxmemory policies"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Use appropriate data types"})," - Match use case"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Enable persistence"})," - Combine RDB + AOF"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Setup replication"})," - For reliability"]}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-bash",children:"# Check Redis connectivity\r\nredis-cli ping\r\n\r\n# Monitor commands in real-time\r\nredis-cli MONITOR\r\n\r\n# Check memory usage\r\nredis-cli INFO memory\r\n\r\n# Find large keys\r\nredis-cli --bigkeys\r\n\r\n# Check slow log\r\nredis-cli SLOWLOG GET 10\r\n\r\n# Clear database\r\nredis-cli FLUSHDB\n"})}),"\n",(0,i.jsx)(r.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:(0,i.jsx)(r.a,{href:"https://redis.io/documentation",children:"Redis Documentation"})}),"\n",(0,i.jsx)(r.li,{children:(0,i.jsx)(r.a,{href:"https://redis.io/commands/",children:"Redis Commands"})}),"\n",(0,i.jsx)(r.li,{children:(0,i.jsx)(r.a,{href:"https://redis.io/topics/cluster-spec",children:"Redis Cluster Specification"})}),"\n",(0,i.jsx)(r.li,{children:(0,i.jsx)(r.a,{href:"https://github.com/redis/redis-py",children:"Python Redis Client"})}),"\n"]})]})}function p(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:function(e,r,n){n.d(r,{R:function(){return o},x:function(){return a}});var s=n(6540);const i={},t=s.createContext(i);function o(e){const r=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(t.Provider,{value:r},e.children)}}}]);