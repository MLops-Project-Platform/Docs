"use strict";(self.webpackChunkmlops_documentation=self.webpackChunkmlops_documentation||[]).push([[7538],{3751:function(e,n,r){r.r(n),r.d(n,{assets:function(){return l},contentTitle:function(){return o},default:function(){return u},frontMatter:function(){return i},metadata:function(){return t},toc:function(){return c}});var t=JSON.parse('{"id":"tools/monitoring","title":"Monitoring & Observability","description":"Overview","source":"@site/docs/tools/monitoring.md","sourceDirName":"tools","slug":"/tools/monitoring","permalink":"/docs/tools/monitoring","draft":false,"unlisted":false,"editUrl":"https://github.com/MLops-Project-Platform/documentation/tree/main/docs/tools/monitoring.md","tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"sidebar_position":9},"sidebar":"tutorialSidebar","previous":{"title":"Message Queues and Event Management","permalink":"/docs/tools/message-queues"},"next":{"title":"CI/CD Pipelines","permalink":"/docs/tools/cicd"}}'),s=r(4848),a=r(8453);const i={sidebar_position:9},o="Monitoring & Observability",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Three Pillars of Observability",id:"three-pillars-of-observability",level:2},{value:"1. Metrics",id:"1-metrics",level:3},{value:"2. Logs",id:"2-logs",level:3},{value:"3. Traces",id:"3-traces",level:3},{value:"Prometheus &amp; Grafana",id:"prometheus--grafana",level:2},{value:"Prometheus Setup",id:"prometheus-setup",level:3},{value:"Prometheus Helm Chart",id:"prometheus-helm-chart",level:3},{value:"PromQL Queries",id:"promql-queries",level:3},{value:"Grafana Dashboards",id:"grafana-dashboards",level:3},{value:"Log Management",id:"log-management",level:2},{value:"ELK Stack (Elasticsearch, Logstash, Kibana)",id:"elk-stack-elasticsearch-logstash-kibana",level:3},{value:"Fluentd Integration",id:"fluentd-integration",level:3},{value:"Graylog Alternative",id:"graylog-alternative",level:3},{value:"Alerting Strategies",id:"alerting-strategies",level:2},{value:"Prometheus Alerting Rules",id:"prometheus-alerting-rules",level:3},{value:"Alert Notification Channels",id:"alert-notification-channels",level:3},{value:"Application Metrics",id:"application-metrics",level:2},{value:"Instrument MLflow with Prometheus",id:"instrument-mlflow-with-prometheus",level:3},{value:"Distributed Tracing",id:"distributed-tracing",level:2},{value:"Jaeger Setup",id:"jaeger-setup",level:3},{value:"Instrument Code with OpenTelemetry",id:"instrument-code-with-opentelemetry",level:3},{value:"Monitoring Best Practices",id:"monitoring-best-practices",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"monitoring--observability",children:"Monitoring & Observability"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(n.p,{children:["Comprehensive monitoring of the MLOps platform includes ",(0,s.jsx)(n.strong,{children:"metrics"}),", ",(0,s.jsx)(n.strong,{children:"logs"}),", and ",(0,s.jsx)(n.strong,{children:"traces"})," across infrastructure, services, and machine learning pipelines."]}),"\n",(0,s.jsx)(n.h2,{id:"three-pillars-of-observability",children:"Three Pillars of Observability"}),"\n",(0,s.jsx)(n.h3,{id:"1-metrics",children:"1. Metrics"}),"\n",(0,s.jsx)(n.p,{children:"Quantifiable measurements at specific points in time:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"CPU, memory, disk usage"}),"\n",(0,s.jsx)(n.li,{children:"Request rate, latency, errors"}),"\n",(0,s.jsx)(n.li,{children:"GPU utilization"}),"\n",(0,s.jsx)(n.li,{children:"Model inference latency"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-logs",children:"2. Logs"}),"\n",(0,s.jsx)(n.p,{children:"Detailed event records with context:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Application logs"}),"\n",(0,s.jsx)(n.li,{children:"System logs"}),"\n",(0,s.jsx)(n.li,{children:"Access logs"}),"\n",(0,s.jsx)(n.li,{children:"Error traces"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"3-traces",children:"3. Traces"}),"\n",(0,s.jsx)(n.p,{children:"Request flow tracking across distributed systems:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"End-to-end request latency"}),"\n",(0,s.jsx)(n.li,{children:"Service dependencies"}),"\n",(0,s.jsx)(n.li,{children:"Bottleneck identification"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prometheus--grafana",children:"Prometheus & Grafana"}),"\n",(0,s.jsx)(n.h3,{id:"prometheus-setup",children:"Prometheus Setup"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"prometheus.yaml:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"global:\r\n  scrape_interval: 15s\r\n  evaluation_interval: 15s\r\n\r\nscrape_configs:\r\n  - job_name: 'kubernetes-apiservers'\r\n    kubernetes_sd_configs:\r\n    - role: endpoints\r\n    scheme: https\r\n    tls_config:\r\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\r\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\r\n\r\n  - job_name: 'kubernetes-nodes'\r\n    kubernetes_sd_configs:\r\n    - role: node\r\n    scheme: https\r\n    tls_config:\r\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\r\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\r\n\r\n  - job_name: 'kubernetes-pods'\r\n    kubernetes_sd_configs:\r\n    - role: pod\r\n    relabel_configs:\r\n    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\r\n      action: keep\r\n      regex: true\r\n\r\n  - job_name: 'mlflow'\r\n    static_configs:\r\n    - targets: ['mlflow:5000']\r\n\r\n  - job_name: 'gpu-metrics'\r\n    static_configs:\r\n    - targets: ['gpu-exporter:9400']\n"})}),"\n",(0,s.jsx)(n.h3,{id:"prometheus-helm-chart",children:"Prometheus Helm Chart"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\r\nhelm repo update\r\n\r\nhelm install prometheus prometheus-community/kube-prometheus-stack \\\r\n  -n monitoring \\\r\n  --create-namespace\n"})}),"\n",(0,s.jsx)(n.h3,{id:"promql-queries",children:"PromQL Queries"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-promql",children:'# CPU usage percentage\r\n(1 - avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100\r\n\r\n# Memory usage\r\nnode_memory_MemTotal_bytes - node_memory_MemAvailable_bytes\r\n\r\n# Pod restart count\r\nrate(kube_pod_container_status_restarts_total[15m])\r\n\r\n# GPU utilization\r\nnvidia_gpu_sm_clock_target\r\n\r\n# Model inference latency (95th percentile)\r\nhistogram_quantile(0.95, rate(model_inference_duration_seconds_bucket[5m]))\r\n\r\n# Request error rate\r\nrate(http_requests_total{status=~"5.."}[1m])\n'})}),"\n",(0,s.jsx)(n.h3,{id:"grafana-dashboards",children:"Grafana Dashboards"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Docker Compose to add Grafana:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'prometheus:\r\n  image: prom/prometheus:latest\r\n  volumes:\r\n    - ./prometheus.yml:/etc/prometheus/prometheus.yml\r\n  ports:\r\n    - "9090:9090"\r\n\r\ngrafana:\r\n  image: grafana/grafana:latest\r\n  ports:\r\n    - "3000:3000"\r\n  environment:\r\n    GF_SECURITY_ADMIN_PASSWORD: admin\r\n  volumes:\r\n    - grafana_storage:/var/lib/grafana\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Dashboard Configuration:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\r\n  "dashboard": {\r\n    "title": "MLOps Platform",\r\n    "panels": [\r\n      {\r\n        "title": "CPU Usage",\r\n        "targets": [\r\n          {\r\n            "expr": "rate(node_cpu_seconds_total[5m])"\r\n          }\r\n        ]\r\n      },\r\n      {\r\n        "title": "GPU Utilization",\r\n        "targets": [\r\n          {\r\n            "expr": "nvidia_gpu_sm_clock_target"\r\n          }\r\n        ]\r\n      },\r\n      {\r\n        "title": "Model Latency (p95)",\r\n        "targets": [\r\n          {\r\n            "expr": "histogram_quantile(0.95, rate(model_inference_duration_seconds_bucket[5m]))"\r\n          }\r\n        ]\r\n      }\r\n    ]\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"log-management",children:"Log Management"}),"\n",(0,s.jsx)(n.h3,{id:"elk-stack-elasticsearch-logstash-kibana",children:"ELK Stack (Elasticsearch, Logstash, Kibana)"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Docker Compose:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'elasticsearch:\r\n  image: docker.elastic.co/elasticsearch/elasticsearch:8.0.0\r\n  environment:\r\n    - discovery.type=single-node\r\n    - xpack.security.enabled=false\r\n  ports:\r\n    - "9200:9200"\r\n\r\nlogstash:\r\n  image: docker.elastic.co/logstash/logstash:8.0.0\r\n  volumes:\r\n    - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf\r\n  ports:\r\n    - "5000:5000"\r\n\r\nkibana:\r\n  image: docker.elastic.co/kibana/kibana:8.0.0\r\n  ports:\r\n    - "5601:5601"\r\n  depends_on:\r\n    - elasticsearch\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Logstash Configuration:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'input {\r\n  tcp {\r\n    port => 5000\r\n    codec => json\r\n  }\r\n}\r\n\r\nfilter {\r\n  if [type] == "pod" {\r\n    mutate {\r\n      add_field => { "kubernetes" => "%{[kubernetes.namespace_name]}" }\r\n    }\r\n  }\r\n}\r\n\r\noutput {\r\n  elasticsearch {\r\n    hosts => ["elasticsearch:9200"]\r\n    index => "logs-%{+YYYY.MM.dd}"\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"fluentd-integration",children:"Fluentd Integration"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Fluentd DaemonSet:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'apiVersion: apps/v1\r\nkind: DaemonSet\r\nmetadata:\r\n  name: fluentd\r\n  namespace: logging\r\nspec:\r\n  selector:\r\n    matchLabels:\r\n      app: fluentd\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: fluentd\r\n    spec:\r\n      containers:\r\n      - name: fluentd\r\n        image: fluent/fluentd-kubernetes-daemonset:v1\r\n        volumeMounts:\r\n        - name: varlog\r\n          mountPath: /var/log\r\n        - name: varlibdockercontainers\r\n          mountPath: /var/lib/docker/containers\r\n          readOnly: true\r\n        env:\r\n        - name: FLUENT_ELASTICSEARCH_HOST\r\n          value: "elasticsearch"\r\n        - name: FLUENT_ELASTICSEARCH_PORT\r\n          value: "9200"\r\n      volumes:\r\n      - name: varlog\r\n        hostPath:\r\n          path: /var/log\r\n      - name: varlibdockercontainers\r\n        hostPath:\r\n          path: /var/lib/docker/containers\n'})}),"\n",(0,s.jsx)(n.h3,{id:"graylog-alternative",children:"Graylog Alternative"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Docker Compose:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'mongodb:\r\n  image: mongo:4.4\r\n  environment:\r\n    MONGO_INITDB_ROOT_USERNAME: root\r\n    MONGO_INITDB_ROOT_PASSWORD: root\r\n\r\nelasticsearch:\r\n  image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0\r\n  environment:\r\n    - discovery.type=single-node\r\n\r\ngraylog:\r\n  image: graylog/graylog:4.0\r\n  environment:\r\n    GRAYLOG_PASSWORD_SECRET: "lengthAtLeast16Chars"\r\n    GRAYLOG_ROOT_PASSWORD_SHA2: "8c6976e5b5410415bde908bd4dee15dfb167a9c873fc4bb8a81f6f2ab448a918"\r\n  ports:\r\n    - "9000:9000"  # Web interface\r\n    - "12201:12201/udp"  # GELF protocol\n'})}),"\n",(0,s.jsx)(n.h2,{id:"alerting-strategies",children:"Alerting Strategies"}),"\n",(0,s.jsx)(n.h3,{id:"prometheus-alerting-rules",children:"Prometheus Alerting Rules"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"alert-rules.yaml:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'groups:\r\n- name: MLOps Alerts\r\n  interval: 30s\r\n  rules:\r\n  - alert: HighCPUUsage\r\n    expr: (1 - avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100 > 80\r\n    for: 5m\r\n    annotations:\r\n      summary: "High CPU usage detected"\r\n      description: "CPU usage is {{ $value }}%"\r\n\r\n  - alert: GPUMemoryExceeded\r\n    expr: nvidia_gpu_memory_used_mb / nvidia_gpu_memory_total_mb > 0.9\r\n    for: 2m\r\n    annotations:\r\n      summary: "GPU memory usage is high"\r\n      description: "GPU {{ $labels.gpu_uuid }} is at {{ $value }}% capacity"\r\n\r\n  - alert: ModelInferenceLatency\r\n    expr: histogram_quantile(0.95, rate(model_inference_duration_seconds_bucket[5m])) > 1\r\n    for: 5m\r\n    annotations:\r\n      summary: "High model inference latency"\r\n      description: "P95 latency is {{ $value }} seconds"\r\n\r\n  - alert: TrainingJobFailed\r\n    expr: training_job_status{status="failed"} > 0\r\n    for: 1m\r\n    annotations:\r\n      summary: "Training job failed"\r\n      description: "Training job {{ $labels.job_id }} has failed"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"alert-notification-channels",children:"Alert Notification Channels"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Slack Integration:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"global:\r\n  resolve_timeout: 5m\r\n\r\nroute:\r\n  receiver: 'slack'\r\n  group_by: ['alertname', 'cluster']\r\n  group_wait: 10s\r\n  group_interval: 10s\r\n  repeat_interval: 12h\r\n\r\nreceivers:\r\n- name: 'slack'\r\n  slack_configs:\r\n  - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'\r\n    channel: '#mlops-alerts'\r\n    text: 'Alert: {{ .GroupLabels.alertname }}'\n"})}),"\n",(0,s.jsx)(n.h2,{id:"application-metrics",children:"Application Metrics"}),"\n",(0,s.jsx)(n.h3,{id:"instrument-mlflow-with-prometheus",children:"Instrument MLflow with Prometheus"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from prometheus_client import Counter, Histogram, Gauge\r\nimport time\r\n\r\n# Define metrics\r\ntraining_jobs = Counter(\r\n    'mlops_training_jobs_total',\r\n    'Total training jobs',\r\n    ['status']\r\n)\r\n\r\ntraining_duration = Histogram(\r\n    'mlops_training_duration_seconds',\r\n    'Training job duration',\r\n    buckets=[60, 300, 600, 1800, 3600, 7200]\r\n)\r\n\r\nmodel_accuracy = Gauge(\r\n    'mlops_model_accuracy',\r\n    'Model accuracy on test set',\r\n    ['model_name', 'version']\r\n)\r\n\r\n# Use metrics in code\r\n@training_duration.time()\r\ndef train_model(config):\r\n    try:\r\n        # Training logic\r\n        accuracy = model.evaluate(test_data)\r\n        model_accuracy.labels(\r\n            model_name=config['name'],\r\n            version=config['version']\r\n        ).set(accuracy)\r\n        training_jobs.labels(status='success').inc()\r\n    except Exception as e:\r\n        training_jobs.labels(status='failed').inc()\r\n        raise\n"})}),"\n",(0,s.jsx)(n.h2,{id:"distributed-tracing",children:"Distributed Tracing"}),"\n",(0,s.jsx)(n.h3,{id:"jaeger-setup",children:"Jaeger Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker run -d --name jaeger \\\r\n  -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\r\n  -p 5775:5775/udp \\\r\n  -p 6831:6831/udp \\\r\n  -p 6832:6832/udp \\\r\n  -p 5778:5778 \\\r\n  -p 16686:16686 \\\r\n  -p 14268:14268 \\\r\n  -p 14250:14250 \\\r\n  -p 9411:9411 \\\r\n  jaegertracing/all-in-one:latest\n"})}),"\n",(0,s.jsx)(n.h3,{id:"instrument-code-with-opentelemetry",children:"Instrument Code with OpenTelemetry"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from opentelemetry import trace, metrics\r\nfrom opentelemetry.exporter.jaeger import JaegerExporter\r\nfrom opentelemetry.sdk.trace import TracerProvider\r\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\r\n\r\njaeger_exporter = JaegerExporter(agent_host_name="localhost", agent_port=6831)\r\ntrace.set_tracer_provider(TracerProvider())\r\ntrace.get_tracer_provider().add_span_processor(\r\n    BatchSpanProcessor(jaeger_exporter)\r\n)\r\n\r\ntracer = trace.get_tracer(__name__)\r\n\r\nwith tracer.start_as_current_span("training") as span:\r\n    span.set_attribute("model.name", "bert")\r\n    span.set_attribute("dataset.size", 10000)\r\n    \r\n    # Training code\r\n    train_model(config)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"monitoring-best-practices",children:"Monitoring Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Set meaningful thresholds"})," - Alert on business metrics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Use correlation"})," - Link metrics, logs, and traces"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monitor the monitor"})," - Ensure monitoring is healthy"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Automate response"})," - Use alerts to trigger actions"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Aggregate data"})," - Summarize metrics at multiple levels"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Retain historical data"})," - Keep data for trend analysis"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://prometheus.io/docs/",children:"Prometheus Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://grafana.com/docs/",children:"Grafana Documentation"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.elastic.co/what-is/elk-stack",children:"ELK Stack Guide"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.jaegertracing.io/docs/",children:"Jaeger Documentation"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:function(e,n,r){r.d(n,{R:function(){return i},x:function(){return o}});var t=r(6540);const s={},a=t.createContext(s);function i(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);